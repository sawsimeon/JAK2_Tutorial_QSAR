---
title: Probing the origins of the Janus kinase 2 inhibitors via quantitative structure
  activityrelationship
author: "Saw Simeon and Nathjanan Jongkon"
date: "13 September 2019"
output: html_document
---

## Figure 2 (Chemical Space of JAK2 inhibitors)
```{r, warning = FALSE, message = FALSE, error = FALSE, tidy= TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")
df$Activity <- ifelse(df$pIC50 > 6, "Active",
                      ifelse((df$pIC50 <= 6) & (df$pIC50 < 5), "Inactive", 
                             "Intermediate"))
library(ggplot2)
library(cowplot)
p <- ggplot(df, aes(MW, ALogP))
p <- p + geom_point(aes(colour = factor(Activity)), size = 3, alpha = 0.3)
p <- p + theme(legend.position = ("none"),
           panel.border = element_rect(linetype = "solid",
                                       colour = "black", fill = NA, size = 1),
           axis.text.x = element_text(colour = "black", size = 10),
           axis.text.y = element_text(colour = "black", size = 10),
           plot.margin = unit(c(1, 1, 1, 1), "cm"),
           axis.title.x = element_text(colour = "black", size = 15, face = "bold"),
           axis.title.y = element_text(colour = "black", size = 15, face = "bold")
           )
print(p)



```


## Figure 3 (Boxplot of Lipinski's rule-of-five descriptors)
```{r, warning = FALSE, message = FALSE, error = FALSE, tidy= TRUE, fig.width = 10, fig.height = 10}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")
df$Activity <- ifelse(df$pIC50 > 6, "Active",
                      ifelse((df$pIC50 <= 6) & (df$pIC50 < 5), "Inactive", 
                             "Intermediate"))
library(ggplot2)
library(cowplot)

p <- ggplot(df, aes(MW, ALogP))
p <- p + geom_point(aes(colour = factor(Activity)), size = 3, alpha = 0.3)
p <- p + theme(legend.position = ("none"),
           panel.border = element_rect(linetype = "solid",
                                       colour = "black", fill = NA, size = 1),
           axis.text.x = element_text(colour = "black", size = 10),
           axis.text.y = element_text(colour = "black", size = 10),
           plot.margin = unit(c(1, 1, 1, 1), "cm"),
           axis.title.x = element_text(colour = "black", size = 15, face = "bold"),
           axis.title.y = element_text(colour = "black", size = 15, face = "bold")
           )

p_1 <- ggplot(df, aes(factor(Activity), ALogP))
p_1 <- p_1 + geom_boxplot(aes(fill = factor(Activity)), alpha = 0.7)
p_1 <- p_1 + theme(legend.position = ("none"),
                   panel.border = element_rect(linetype = "solid",
                                               colour = "black", fill = NA, size = 1),
                   axis.text.x = element_text(colour = "black", size = 15),
                   axis.text.y = element_text(colour = "black", size = 15),
                   plot.margin = unit(c(1, 1, 1, 1), "cm"),
                   axis.title.y = element_text(size = 20, face = "bold"),
                   axis.title.x = element_blank())

p_2 <- ggplot(df, aes(factor(Activity), nHBAcc))
p_2 <- p_2 + geom_boxplot(aes(fill = factor(Activity)), alpha = 0.7)
p_2 <- p_2 + theme(legend.position = ("none"),
                   panel.border = element_rect(linetype = "solid",
                                               colour = "black", fill = NA, size = 1),
                   axis.text.x = element_text(colour = "black", size = 15),
                   axis.text.y = element_text(colour = "black", size = 15),
                   plot.margin = unit(c(1, 1, 1, 1), "cm"),
                   axis.title.y = element_text(size = 20, face = "bold"),
                   axis.title.x = element_blank())

p_3 <- ggplot(df, aes(factor(Activity), nHBDon))
p_3 <- p_3 + geom_boxplot(aes(fill = factor(Activity)), alpha = 0.7)
p_3 <- p_3 + theme(legend.position = ("none"),
                   panel.border = element_rect(linetype = "solid",
                                               colour = "black", fill = NA, size = 1),
                   axis.text.x = element_text(colour = "black", size = 15),
                   axis.text.y = element_text(colour = "black", size = 15),
                   plot.margin = unit(c(1, 1, 1, 1), "cm"),
                   axis.title.y = element_text(size = 20, face = "bold"),
                   axis.title.x = element_blank())

p_4 <- ggplot(df, aes(factor(Activity), MW))
p_4 <- p_4 + geom_boxplot(aes(fill = factor(Activity)), alpha = 0.7)
p_4 <- p_4 + theme(legend.position = ("none"),
                   panel.border = element_rect(linetype = "solid",
                                               colour = "black", fill = NA, size = 1),
                   axis.text.x = element_text(colour = "black", size = 15),
                   axis.text.y = element_text(colour = "black", size = 15),
                   plot.margin = unit(c(1, 1, 1, 0.4), "cm"),
                   axis.title.y = element_text(size = 20, face = "bold"),
                   axis.title.x = element_blank()) 

library(cowplot)
plot_grid(p_1, p_2, p_3, p_4)


```



## Figure 4. Intercorrelation matrix of the descriptors
```{r, warning = FALSE, message = FALSE, error = FALSE, tidy= TRUE, fig.width = 10, fig.height = 10}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
corrplot(cor(filtered_descriptors))

```


## Table 1. Performance Summary (Random Forest)
```{r, warning = FALSE, message = FALSE, error = FALSE, tidy= TRUE, cache= TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)
library(randomForest)

randomForest_training <- function(x){
  library(randomForest)
  
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    
    
  x <- na.omit(x)
  para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    
    
    #model_train <- ranger::ranger(pIC50~., data = Train, write.forest = TRUE, save.memory = TRUE)
    model_train <- randomForest::randomForest(pIC50~., data = Train)
    #actual <- train$Activity
    #prediction <- predict(model_train, Train)
    #prediction <- prediction$predictions
    prediction <- as.numeric(model_train$predicted)
    
    #prediction <- predict(model, Train)
    value <- data.frame(obs = Train$pIC50, pred = prediction)
    rm(para)
    rm(Train)
    rm(Test)
    rm(model_train)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
mean_and_sd <- function(x) {
  c(round(rowMeans(x, na.rm = TRUE), digits = 2),
    round(genefilter::rowSds(x, na.rm = TRUE), digits = 2))
}
randomForest_train <- function(x) {
  ok <- randomForest_training(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}
rf_cross_validation <- function(x){
  library(randomForest)
  
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    cool <- na.omit(x)
    para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    myData <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    rm(Test)
    k = 10
    index <- sample(1:k, nrow(myData), replace = TRUE)
    folds <- 1:k
    myRes <- data.frame()
    for (j in 1:k) {
      training <- subset(myData, index %in% folds[-j])
    testing <- subset(myData, index %in% c(j))
    #model_train <- ranger::ranger(pIC50~., data = training, write.forest = TRUE, save.memory = TRUE)
    model_train <- randomForest::randomForest(pIC50~., data = training)
    prediction <- predict(model_train, testing)
   # prediction <- prediction$predictions
    
    ok <- data.frame(obs = testing$pIC50, pred = prediction)
    value <- rbind(myRes, ok)
    }
    rm(myData)
    rm(para)
    rm(in_trian_para)
    rm(training)
    rm(testing)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
}
rf_10_CV <- function(x) {
  ok <- rf_cross_validation(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}
randomForest_testing <- function(x){
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    x <- na.omit(x)
    para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    #model_train <- ranger::ranger(pIC50~., data = Train, write.forest = TRUE, save.memory = TRUE)
    model_train <- randomForest::randomForest(pIC50~., data = Train)
    #actual <- train$Activity
    prediction <- predict(model_train, Test)
    #prediction <- prediction$predictions
    value <- data.frame(obs = Test$pIC50, pred = prediction)
    rm(Train)
    rm(Test)
    rm(para)
    rm(in_train_para)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
randomForest_test <- function(x) {
  ok <- randomForest_testing(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}


randomForest_train(df_data)
rf_10_CV(df_data)
randomForest_test(df_data)

```


## Tabel 1 Decision Tree
```{r, wraning = FALSE, message = FALSE, eval = TRUE, error = FALSE, tidy = TRUE, cache=TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)

Decision_Tree_training <- function(x){
  library(rpart)
  library(caret)
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    
    
  cool <- na.omit(x)
  para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
mod_rpart <- caret::train(pIC50 ~ .,
                   method = "rpart",
                   data = Train,
                   tuneLength = 50, 
                   metric = "RMSE",
                   trControl = caret::trainControl(method = "repeatedcv",
                                            number = 10,
                                            repeats = 1))
    
    model_train <- rpart::rpart(pIC50~., data = Train,
                                control = rpart::rpart.control(cp = mod_rpart$bestTune))
    #actual <- train$Activity
    prediction <- predict(model_train, Train)
   # prediction <- prediction$predictions
    
    #prediction <- predict(model, Train)
    value <- data.frame(obs = Train$pIC50, pred = prediction)
    rm(para)
    rm(Train)
    rm(Test)
    rm(model_train)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
mean_and_sd <- function(x) {
  c(round(rowMeans(x, na.rm = TRUE), digits = 2),
    round(genefilter::rowSds(x, na.rm = TRUE), digits = 2))
}
DT_train <- function(x) {
  ok <- Decision_Tree_training(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}
Decision_Tree_cross_validation <- function(x){
  library(randomForest)
  library(caret)
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    cool <- na.omit(x)
    para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    myData <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    rm(Test)
    k = 10
    index <- sample(1:k, nrow(myData), replace = TRUE)
    folds <- 1:k
    myRes <- data.frame()
    for (j in 1:k) {
      training <- subset(myData, index %in% folds[-j])
    testing <- subset(myData, index %in% c(j))
    mod_rpart <- caret::train(pIC50 ~ .,
                   method = "rpart",
                   data = training,
                   tuneLength = 50, 
                   metric = "RMSE",
                   trControl = caret::trainControl(method = "repeatedcv",
                                            number = 10,
                                            repeats = 1))
    model_train <- rpart::rpart(pIC50~., data = training,
                                control = rpart::rpart.control(cp = mod_rpart$bestTune))
    prediction <- predict(model_train, testing)
    #prediction <- prediction$predictions
    
    ok <- data.frame(obs = testing$pIC50, pred = prediction)
    value <- rbind(myRes, ok)
    }
    rm(myData)
    rm(para)
    rm(in_trian_para)
    rm(training)
    rm(testing)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
}
DT_10_CV <- function(x) {
  ok <- Decision_Tree_cross_validation(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}
decision_tree_testing <- function(x){
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    cool <- na.omit(x)
    para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    mod_rpart <- caret::train(pIC50 ~ .,
                   method = "rpart",
                   data = Train,
                   tuneLength = 10, 
                   metric = "RMSE",
                   trControl = caret::trainControl(method = "repeatedcv",
                                            number = 10,
                                            repeats = 1))
    model_train <- rpart::rpart(pIC50~., data = Train,
                                control = rpart::rpart.control(cp = mod_rpart$bestTune))
    #actual <- train$Activity
    prediction <- predict(model_train, Test)
    #prediction <- prediction$predictions
    value <- data.frame(obs = Test$pIC50, pred = prediction)
    rm(Train)
    rm(Test)
    rm(para)
    rm(in_train_para)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
DT_test <- function(x) {
  ok <- decision_tree_testing(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}


DT_train(df_data)
DT_10_CV(df_data)
DT_test(df_data)


```


## Tabel 1 Support vector Machine
```{r, wraning = FALSE, message = FALSE, eval = TRUE, error = FALSE, tidy = TRUE, cache=TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)

SVM_training <- function(x){
  library(rpart)
  
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    
    
  x <- na.omit(x)
  para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    
    
    model_train <- e1071::svm(pIC50~., data = Train)
    #actual <- train$Activity
    prediction <- predict(model_train, Train)
   # prediction <- prediction$predictions
    
    #prediction <- predict(model, Train)
    value <- data.frame(obs = Train$pIC50, pred = prediction)
    rm(para)
    rm(Train)
    rm(Test)
    rm(model_train)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
mean_and_sd <- function(x) {
  c(round(rowMeans(x, na.rm = TRUE), digits = 2),
    round(genefilter::rowSds(x, na.rm = TRUE), digits = 2))
}
SVM_train <- function(x) {
  ok <- SVM_training(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}

SVM_cross_validation <- function(x){
  library(randomForest)
  
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    cool <- na.omit(x)
    para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    myData <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    rm(Test)
    k = 10
    index <- sample(1:k, nrow(myData), replace = TRUE)
    folds <- 1:k
    myRes <- data.frame()
    for (j in 1:k) {
      training <- subset(myData, index %in% folds[-j])
    testing <- subset(myData, index %in% c(j))
    model_train <- e1071::svm(pIC50~., data = training)
    prediction <- predict(model_train, testing)
    #prediction <- prediction$predictions
    
    ok <- data.frame(obs = testing$pIC50, pred = prediction)
    value <- rbind(myRes, ok)
    }
    rm(myData)
    rm(para)
    rm(in_trian_para)
    rm(training)
    rm(testing)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
}
SVM_10_CV <- function(x) {
  ok <- SVM_cross_validation(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}
SVM_testing <- function(x){
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    x <- na.omit(x)
    para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    model_train <- e1071::svm(pIC50~., data = Train)
    #actual <- train$Activity
    prediction <- predict(model_train, Test)
    #prediction <- prediction$predictions
    value <- data.frame(obs = Test$pIC50, pred = prediction)
    rm(Train)
    rm(Test)
    rm(para)
    rm(in_train_para)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
SVM_test <- function(x) {
  ok <- SVM_testing(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}


SVM_train(df_data)
SVM_10_CV(df_data)
SVM_test(df_data)


```


## Tabel 1 Deep neural network
```{r, wraning = FALSE, message = FALSE, eval = TRUE, error = FALSE, tidy = TRUE, cache=TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)

Deep_NN_training <- function(x){
  library(rpart)
  library(keras)
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
    library(keras)
    
  cool <- na.omit(x)
  para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    
    Train_data <- as.matrix(Train[, 2:34])
    Train_target <- as.array(Train[, 1])
    Test_data <- as.matrix(Test[, 2:34])
    Test_target <- as.array(Test[, 1])
    
    build_model <- function() {
  model <- keras_model_sequential() %>%
    layer_dense(units = 64, activation = "relu",
                input_shape = dim(Train_data)[[2]]) %>%
    layer_dense(units = 64, activation = "relu") %>%
    layer_dense(units = 1)
  model %>% compile(
    optimizer = "rmsprop", 
    loss = "mse", 
    metrics = c("mae")
  )
}



model <- build_model()

model %>% fit(Train_data, Train_target,
              epochs = 80, batch_size = 16, verbose = 0)

prediction <- model %>% predict_on_batch(Train_data)

    #model_train <- e1071::svm(pIC50~., data = Train)
    #actual <- train$Activity
   # prediction <- predict(model_train, Train)
   # prediction <- prediction$predictions
    
    #prediction <- predict(model, Train)
    value <- data.frame(obs = Train$pIC50, pred = prediction)
    rm(para)
    rm(Train)
    rm(Test)
    rm(Train_data)
    rm(Train_target)
    rm(Test_data)
    rm(Test_target)
    rm(model)
    rm(build_model)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
mean_and_sd <- function(x) {
  c(round(rowMeans(x, na.rm = TRUE), digits = 2),
    round(genefilter::rowSds(x, na.rm = TRUE), digits = 2))
}

Deep_NN_train <- function(x) {
  ok <- Deep_NN_training(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}


Deep_NN_cross_validation <- function(x){
  library(randomForest)
  library(keras)
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    library(keras)
    cool <- na.omit(x)
    para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    myData <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    rm(Test)
    k = 10
    index <- sample(1:k, nrow(myData), replace = TRUE)
    folds <- 1:k
    myRes <- data.frame()
    for (j in 1:k) {
      training <- subset(myData, index %in% folds[-j])
    testing <- subset(myData, index %in% c(j))
    
    training_data <- as.matrix(training[, 2:34])
    training_target <- as.array(training[, 1])
    testing_data <- as.matrix(testing[, 2:34])
    testing_target <- as.array(testing[, 1])
    
    build_model <- function() {
  model <- keras_model_sequential() %>%
    layer_dense(units = 64, activation = "relu",
                input_shape = dim(training_data)[[2]]) %>%
    layer_dense(units = 64, activation = "relu") %>%
    layer_dense(units = 1)
  model %>% compile(
    optimizer = "rmsprop", 
    loss = "mse", 
    metrics = c("mae")
  )
}



model <- build_model()

model %>% fit(training_data, training_target,
              epochs = 80, batch_size = 16, verbose = 0)

prediction <- model %>% predict_on_batch(testing_data)
    #prediction <- prediction$predictions
    
    ok <- data.frame(obs = testing$pIC50, pred = prediction)
    value <- rbind(myRes, ok)
    }
    rm(myData)
    rm(para)
    rm(Test)
    rm(model)
    rm(in_trian_para)
    rm(training)
    rm(testing)
    rm(prediction)
    rm(training_data)
    rm(traning_target)
    rm(testing_data)
    rm(testing_target)
    rm(build_model)
    rm(ok)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
}
Deep_NN_10_CV <- function(x) {
  ok <- Deep_NN_cross_validation(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}



Deep_NN_testing <- function(x){
  library(rpart)
  library(keras)
  library(parallel)
  library(doSNOW)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  R2 <- function(y, equation, ... ){
  1 - (sum((y-predict(equation))^2)/sum((y-mean(y))^2))
}
rm2 <- function(y, x, ... ){  
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) { 
    return(R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x)))))))
  } else { 
    return(R2(y,(lm(y ~ x))))
  } 
}
rm2.reverse <- function(y, x, ... ){
  return(R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))
}
average.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))+ R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y))))))))/2)
  } else { 
    return(((R2(y,(lm(y ~ x))))  + (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  )/2)
  }
}
delta.rm2 <- function(y, x, ... ){
  if ((R2(y,(lm(y ~ x)))) > R2(y,(lm(y ~ -1 + x)))) {
    return(abs((R2(y,(lm(y ~ x)))*( 1-(sqrt(R2(y,(lm(y ~ x)))-R2(y,(lm(y ~ -1 + x))))))  -  R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))))
  } else { 
    return(abs((R2(y,(lm(y ~ x)))) - (R2(x,(lm(x ~ y)))*( 1-(sqrt(R2(x,(lm(x ~ y)))-R2(x,(lm(x ~ -1 + y)))))))  ))
  }
}
  
  results <- list(100)
  results <- foreach(i = 1:100 ) %dopar% {
    
  library(keras)
    
  cool <- na.omit(x)
  para <- dplyr::sample_n(cool, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    
    Train_data <- as.matrix(Train[, 2:34])
    Train_target <- as.array(Train[, 1])
    Test_data <- as.matrix(Test[, 2:34])
    Test_target <- as.array(Test[, 1])
    
    build_model <- function() {
  model <- keras_model_sequential() %>%
    layer_dense(units = 64, activation = "relu",
                input_shape = dim(Train_data)[[2]]) %>%
    layer_dense(units = 64, activation = "relu") %>%
    layer_dense(units = 1)
  model %>% compile(
    optimizer = "rmsprop", 
    loss = "mse", 
    metrics = c("mae")
  )
}



model <- build_model()

model %>% fit(Train_data, Train_target,
              epochs = 80, batch_size = 16, verbose = 0)

prediction <- model %>% predict_on_batch(Test_data)

    #model_train <- e1071::svm(pIC50~., data = Train)
    #actual <- train$Activity
   # prediction <- predict(model_train, Train)
   # prediction <- prediction$predictions
    
    #prediction <- predict(model, Train)
    value <- data.frame(obs = Test$pIC50, pred = prediction)
    rm(para)
    rm(Train)
    rm(Test)
    rm(model)
    rm(build_model)
    rm(Train_data)
    rm(Train_target)
    rm(Test_data)
    rm(Test_target)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    result <- caret::defaultSummary(value)
    result_rm2 <- rm2(value$obs, value$pred)
    names(result_rm2) <- "rm2"
    results_reverse <- rm2.reverse(value$obs, value$pred)
    names(results_reverse) <- "reverse.rm2"
    result_average_rm2 <- average.rm2(value$obs, value$pred)
    names(result_average_rm2) <- "average.rm2"
    result_delta <- delta.rm2(value$obs, value$pred)
    names(result_delta) <- "delta.rm"
    
    results[[i]] <- c(result, result_rm2, results_reverse, result_average_rm2, result_delta)
  }
  return(results)
  stopCluster(cl)
}
mean_and_sd <- function(x) {
  c(round(rowMeans(x, na.rm = TRUE), digits = 2),
    round(genefilter::rowSds(x, na.rm = TRUE), digits = 2))
}

Deep_NN_test <- function(x) {
  ok <- Deep_NN_testing(x)
  data <- data.frame(ok)
  result <- mean_and_sd(data)
  df <- data.frame(result)
  R2_and_RMSE <- t(df)
  label <- c("RMSE_Mean", "Rsquared_Mean", "MAE_mean", "RM2_Mean", "Reverse_RM2_Mean", "Average_RM2_Mean", "Delta_RM2_Mean",
             "RMSE_SD", "Rsquared_SD", "MAE_SD", "RM2_SD", "Reverse_RM2_SD", "Average_RM2_SD", "Delta_RM2_SD")
  colnames(R2_and_RMSE) <- label
  return(R2_and_RMSE)
}





Deep_NN_train(df_data)
Deep_NN_10_CV(df_data)
Deep_NN_test(df_data)


```






## Figure 5. Y-Scrambling Plot
```{r, warning = FALSE, message = FALSE, eval = TRUE, error = FALSE, tidy= TRUE, fig.width = 10, fig.height = 10, cache= TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)
library(pls)

scrambling_R2 <- function(x) {
  library(doSNOW)
  library(foreach)
  library(parallel)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  results <- list(50)
  results <- foreach (i = 1:50) %dopar% {
    x <- na.omit(x)
    para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    pIC50 <- gtools::permute(Train$pIC50)
    pIC50 <- data.frame(pIC50)
    fake_data <- cbind(pIC50, Train[, 2:ncol(Train)])
    fit <- ranger::ranger(pIC50~., data = fake_data, write.forest = TRUE, save.memory = TRUE)
    prediction <- predict(fit, Train)
    prediction <- prediction$predictions
    value <- data.frame(obs = Train$pIC50, pred = as.numeric(prediction))
    
    rm(fit)
    rm(prediction)
    labeling <- c("obs", "pred")
    colnames(value) <- labeling
    results[[i]] <- caret::defaultSummary(value)
  }
  R2 <- data.frame(results)
  R2 <- t(R2)
  R2 <- as.numeric(R2[,2])
  R2 <- round(R2, digits = 5)
  return(R2)
  stopCluster(cl)
}
real_R2 <- function(x) {
  x <- na.omit(x)
  para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
  in_train_para <- sample(nrow(para),
                          size = as.integer(nrow(para) * 0.8),
                          replace = FALSE)
  Train <- para[in_train_para, ]
  Test <- para[-in_train_para, ]
  #ctrl <- caret::trainControl(method = "repeatedcv", number = 10, repeats = 1)
  #tune <- caret::train(pIC50~., data = Train, method = "ranger",
  #                       trControl  = ctrl, tuneLength = 5)
  fit <- ranger::ranger(pIC50~., data = Train, write.forest = TRUE, save.memory = TRUE)
  prediction <- predict(fit, Train)
  prediction <- prediction$predictions
  value <- data.frame(obs = Train$pIC50, pred = as.numeric(prediction))
  labeling <- c("obs", "pred")
  colnames(value) <- labeling
  result <- caret::defaultSummary(value)
  R2 <- as.data.frame(result)
  R2 <- R2[2, ]
  R2 <- round(R2, digits = 5)
  return(R2)
}
scrambling_Q2 <- function(x) {
  library(doSNOW)
  library(foreach)
  library(parallel)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  results <- list(50)
  results <- foreach (i = 1:50) %dopar% {
    para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
  in_train_para <- sample(nrow(para),
                          size = as.integer(nrow(para) * 0.8),
                          replace = FALSE)
  Train <- para[in_train_para, ]
  Test <- para[-in_train_para, ]
    pIC50 <- gtools::permute(Train$pIC50)
    pIC50 <- data.frame(pIC50)
    myData <- cbind(pIC50, Train[, 2:ncol(x)])
    k = 10
    index <- sample(1:k, nrow(myData), replace = TRUE)
    folds <- 1:k
    myRes = data.frame()
    for (j in 1:k) {
      training <- subset(myData, index %in% folds[-j])
      testing <- subset(myData, index %in% c(j))
      #pIC50 <- gtools::permute(training$pIC50)
      #pIC50 <- data.frame(pIC50)
      #fake_data <- cbind(pIC50, training[2:ncol(training)])
      fit <- ranger::ranger(pIC50~., data = training, write.forest = TRUE, save.memory = TRUE)
      
      
      #actual <- train$Activity
      prediction <- predict(fit, testing)
      prediction <- prediction$predictions
      value <- data.frame(obs = testing$pIC50, pred = as.numeric(prediction))
      
      #fit <- randomForest::randomForest(pIC50~., data = training, mtry = tune$bestTune[[1]])
      #prediction <- predict(fit, testing)
      #value <- data.frame( obs = testing$pIC50, pred = prediction)
      myRes <- rbind(myRes, value)}
    value <- myRes
    labeling <- c("obs", "pred")
    rm(tune)
    rm(fit)
    rm(prediction)
    rm(ctrl)
    colnames(value) <- labeling
    results[[i]] <- caret::defaultSummary(value)
  }
  Q2 <- data.frame(results)
  Q2 <- t(Q2)
  Q2 <- as.numeric(Q2[,2])
  Q2 <- round(Q2, digits = 5)
  return(Q2)
  stopCluster(cl)
}
real_Q2 <- function(x) {
  para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
  in_train_para <- sample(nrow(para),
                          size = as.integer(nrow(para) * 0.8),
                          replace = FALSE)
  Train <- para[in_train_para, ]
  Test <- para[-in_train_para, ]
  myData <- Train
  k = 10
  index <- sample(1:k, nrow(myData), replace = TRUE)
  folds <- 1:k
  myRes <- data.frame()
  for (j in 1:k) {
    training <- subset(myData, index %in% folds[-j])
    testing <- subset(myData, index %in% c(j))
    #ctrl <- caret::trainControl(method = "repeatedcv", number = 10, repeats = 1)
    #tune <- caret::train(pIC50~., data = training, method = "pls",
    #              trControl  = ctrl, tuneLength = 5)
    fit <- ranger::ranger(pIC50~., data = training, write.forest = TRUE, save.memory = TRUE)
    #fit <- ranger::ranger(pIC50~., data = training, write.forest = TRUE, save.memory = TRUE)
    #actual <- train$Activity
    prediction <- predict(fit, testing)
    prediction <- prediction$predictions
    value <- data.frame(obs = testing$pIC50, pred = as.numeric(prediction))
    #fit <- randomForest(pIC50~., data = training, mtry = tune$bestTune[[1]])
    #prediction <- predict(fit, testing)
    #value <- data.frame(obs = testing$pIC50, pred = prediction)
    myRes <- rbind(myRes, value)
  }
  value <- myRes
  labeling <- c("obs", "pred")
  colnames(value) <- labeling
  result <- caret::defaultSummary(value)
  Q2 <- as.data.frame(result)
  Q2 <- Q2[2, ]
  Q2 <- round(Q2, digits = 5)
  return(Q2)
}
data_pre <- function(x) {
  fake_R2 <- scrambling_R2(x)
  real_R2 <- real_R2(x)
  fake_Q2 <- scrambling_Q2(x)
  real_Q2 <- real_Q2(x)
  fake_R2 <- as.data.frame(fake_R2)
  fake_R2$Label <- "Fake"
  real_R2 <- as.data.frame(real_R2)
  real_R2$Label <- "Real"
  fake_Q2 <- as.data.frame(fake_Q2)
  fake_Q2$Label <- "Fake"
  real_Q2 <- as.data.frame(real_Q2)
  real_Q2$Label <- "Real"
  fake <- cbind(fake_R2, fake_Q2)
  real <- cbind(real_R2, real_Q2)
  combine <- data.frame(fake, real)
  return(combine)
}
plot_scrambling_data <- function(x){
  ok <- data_pre(x)
  colnames(ok) <- c("R2", "Label", "Q2", "Label", "R2", "Label", "Q2", "Label")
  R2 <- ok[c(1, 5)]
  R2 <- reshape2::melt(R2)
  R2 <- R2$value
  R2 <- data.frame(R2)
  Q2 <- ok[c(3, 7)]
  Q2 <- reshape2::melt(Q2)
  Q2 <- Q2$value
  Q2 <- data.frame(Q2)
  Label <- c("Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake",
             "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake",
             "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake",
             "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake",
             "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake",
             "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake", "Fake",
             "Fake", "Fake", "Real", "Real", "Real", "Real", "Real", "Real",
             "Real", "Real", "Real", "Real", "Real", "Real", "Real", "Real",
             "Real", "Real", "Real", "Real", "Real", "Real", "Real", "Real",
             "Real", "Real", "Real", "Real", "Real", "Real", "Real", "Real",
             "Real", "Real", "Real", "Real", "Real", "Real", "Real", "Real",
             "Real", "Real", "Real", "Real", "Real", "Real", "Real", "Real",
             "Real", "Real", "Real", "Real")
  data <- cbind(R2, Q2, Label)
  return(data)
}

data_scramb <- plot_scrambling_data(df_data)
library(ggplot2)
plot_scramb <- ggplot(data_scramb, aes(x = R2, y = Q2, colour = Label)) +
    geom_point(size = 7, colour = "black", aes(fill = factor(Label)), pch = 21, alpha = 0.8) +
    theme(
      legend.position = ("none"),
      #axis.text = element_blank(),
      panel.border = element_rect(linetype = "solid", colour = "black", fill = NA, size = 1)) +
    xlab("") + ylab("") + 
    labs(y = expression(paste(italic(Q^2)))) +
    labs(x = expression(paste(italic(R^2)))) +
    scale_x_continuous(limits = c(0, 1), breaks = seq(from = 0, to = 1, by = 0.5)) +
    scale_y_continuous(limits = c(0, 1), breaks = seq(from = 0, to = 1, by = 0.5)) 
  #coord_cartesian(ylim = c(0, 1), xlim = c(0, 1))
print(plot_scramb)



```

## Feature Importance Plot

```{r, warning = FALSE, message = FALSE, error = FALSE, tidy= TRUE, fig.width = 8, fig.height = 16, cache= TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)
library(pls)


randomForest_feature_importance <- function(x) {
  library(doSNOW)
  library(foreach)
  library(parallel)
  cl <- makeCluster(8)
  registerDoSNOW(cl)
  
  results <- list(100)
  results <- foreach (i = 1:100) %dopar% {
    x <- na.omit(x)
    set.seed(i)
    para <- dplyr::sample_n(x, size = 2370, replace = TRUE)
    set.seed(i)
    in_train_para <- sample(nrow(para),
                            size = as.integer(nrow(para) * 0.8),
                            replace = FALSE)
    Train <- para[in_train_para, ]
    Test <- para[-in_train_para, ]
    rm(in_train_para)
    rm(Test)
    set.seed(i)
    model <- ranger::ranger(pIC50~., data = Train, importance = 'impurity',
                                  write.forest = TRUE, save.memory = TRUE)
    rm(Train)
    importance <- model$variable.importance
    results[[i]] <- importance
  }
  return(results)
  stopCluster(cl)
}

set.seed(10)
results_feature_importance_RF <- randomForest_feature_importance(df_data)
data1 <- data.frame(results_feature_importance_RF)
data1 <- cbind(features = rownames(data1), data1)
library(reshape2)
data_melt <- suppressWarnings(melt(data1, id.vars = "features"))
#data_melt <- melt(data1, id.vars = "features")
data_melt$features <- factor(data_melt$features)
library(ggplot2)
set.seed(1)
plot_feature <- ggplot(data_melt, aes(x = reorder(features, value, FUN = median), y = value)) +
  geom_boxplot(fill = "#F8766D", colour = "black", alpha = 0.5) +
  theme_bw() + xlab("") + ylab("Gini Index") + coord_flip() + theme(
    axis.text.y = element_text(size = 20, colour = "black"),
    axis.text.x = element_text(size = 20, colour = "black"),
    #axis.title.x = element_blank(),
    plot.margin = unit(c(1, 1, 1, 1), "cm"),
    panel.border = element_rect(linetype = "solid", colour = "black", fill = NA, size = 1),
    axis.title = element_text(size = 25, face = "bold", colour = "black")
  )
plot_feature


```


## William Plot
```{r, warning = FALSE, message = FALSE, error = FALSE, tidy= TRUE, fig.width = 7, fig.height = 7, cache=TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)

file <- function(x) {
  library(randomForest)
  library(caret)
  library(ranger)
  set.seed(10)
  para <- x
  set.seed(3)
  in_train_para <- sample(nrow(para),
                          size = as.integer(nrow(para) * 0.8),
                          replace = FALSE)
  set.seed(4)
  Train <- para[in_train_para, ]
  Test  <- para[-in_train_para, ]
  
  model <- ranger::ranger(pIC50~., data = Train, write.forest = TRUE, save.memory = TRUE)
  #actual <- train$Activity
  prediction <- predict(model, Train)
  prediction_Internal <- prediction$predictions
  value <- data.frame(obs = Train$pIC50, pred = prediction_Internal)
  labeling <- c("obs", "pred")
  colnames(value) <- labeling
  value$Label <- c("Internal")
  prediction_External <- predict(model, Test)
  prediction_External <- prediction_External$predictions
  value_external <- data.frame(obs = Test$pIC50, pred = prediction_External)
  colnames(value_external) <- labeling
  value_external$Label <- c("External")
  results <- rbind(value, value_external)
  return(results)
}
get_leverage <- function(x) {
  file <- file(x)
  x <- file[, 1]
  y <- file[, 2]
  data <- data.frame(x, y)
  error <- y-x
  label <- file[3]
  fit = lm(y~x,data = data)
  hv <- as.data.frame(hatvalues(fit))
  std.error = scale(error)
  df <- data.frame(hv, std.error, label)
  names(df) <- c("hv", "std.error", "Label")
  return(df)
}
plot_william <- function(x, title) {
  library(ggplot2)
  library(cowplot)
  ok <- get_leverage(x)
  df <- data.frame(ok)
  good <- ggplot(df, aes(hv, std.error)) + 
  geom_point(aes(color = Label), alpha = .20, size = 6) + 
  ggtitle(title) +
       xlab("Leverage") + ylab("Standardized Residuals") + 
       geom_hline(yintercept = 3, color = "red", linetype = 2) +
    geom_hline(yintercept = -3, color = "red", linetype = 2) +
     theme(
      panel.border = element_rect(linetype = "solid", colour = "black",
                                  fill = NA, size = 1),
    plot.title = element_text(size = 30, color = "black", face = "bold"),
      axis.text.y = element_text(size = 20, colour = "black"),
    axis.text.x = element_text(size = 20, colour = "black"),
    axis.title.x = element_text(size = 30, color = "black", face = "bold"),
    axis.title.y = element_text(size = 30, color = "black", face = "bold"),
    
      legend.position = ("none"))
  return(good)
  
}


plot_william <- plot_william(df_data, title = " ")
h <- 3*((dim(df_data)[2] - 1) + 1) / dim(df_data)[1]*0.8
plot_william + geom_vline(xintercept = h, linetype = 2, color = "red")


```




## Scatter Plot
```{r, warning = FALSE, message = FALSE, error = FALSE, tidy= TRUE, fig.width = 7, fig.height = 7, cache=TRUE}

df <- read.csv("C:/Users/Saw/Documents/GE paper/QSAR_JAK2/Final_JAK2_QSAR.csv")

df_des <- df[, 74:380]
library(caret)
library(corrplot)
yes <- df_des[, -nearZeroVar(df_des)]
raw <- cor(yes)
raw_2 <- raw[1: ncol(raw), 1:ncol(raw)]
high <- findCorrelation(raw_2, cutoff = 0.7)
filtered_descriptors <- yes[, -high]
filtered_descriptors_norm <- as.data.frame(t(apply(filtered_descriptors, 1, function(x) (x - min(x))/(max(x)-min(x)))))
df_data <- data.frame(pIC50 = df$pIC50, filtered_descriptors_norm)

file <- function(x) {
  library(randomForest)
  library(caret)
  library(ranger)
  set.seed(10)
  para <- x
  set.seed(3)
  in_train_para <- sample(nrow(para),
                          size = as.integer(nrow(para) * 0.8),
                          replace = FALSE)
  set.seed(4)
  Train <- para[in_train_para, ]
  Test  <- para[-in_train_para, ]
  
  model <- ranger::ranger(pIC50~., data = Train, write.forest = TRUE, save.memory = TRUE)
  #actual <- train$Activity
  prediction <- predict(model, Train)
  prediction_Internal <- prediction$predictions
  value <- data.frame(obs = Train$pIC50, pred = prediction_Internal)
  labeling <- c("obs", "pred")
  colnames(value) <- labeling
  value$Label <- c("Internal")
  prediction_External <- predict(model, Test)
  prediction_External <- prediction_External$predictions
  value_external <- data.frame(obs = Test$pIC50, pred = prediction_External)
  colnames(value_external) <- labeling
  value_external$Label <- c("External")
  results <- rbind(value, value_external)
  return(results)
}

get_interval <- function(x) {
  file <- file(x)
  x <- file[, 1]
  y <- file[, 2]
  label <- file[3]
  fit <- lm(y~x)
  pred.int <- predict(fit, interval = "prediction")
  pred.lower = pred.int[,2]
  pred.upper = pred.int[,3]
  df <- cbind(x, y, label, pred.lower, pred.upper)
  return(df)
}

plot_graph_interval <- function(x) {
  library(ggplot2)
  ok <- get_interval(x)
  good <- ggplot(ok, aes(x = x)) +
    geom_point(size = 7, colour = "black", pch = 21, alpha= 0.4,
               aes(y = y, fill = factor(Label))) +
    geom_line(aes(y = pred.lower), size = 1.5, colour = "grey", linetype = 2) +
    geom_line(aes(y = pred.upper), size = 1.5, colour = "grey", linetype = 2) +
    geom_smooth(aes(y = y), method='lm', linetype = 1, colour = "black") + 
    xlab(expression(paste('Predicted ', pIC[50]))) + ylab(expression(paste('Experimental ', pIC[50]))) +
    #geom_abline(intercept = ok$pred.lower[[1]], linetype = 2, size = 1.5, colour = "grey") +
    #geom_abline(intercept = ok$pred.upper[[1]], linetype = 2, size = 1.5, colour = "grey") +
    theme(
      panel.border = element_rect(linetype = "solid", colour = "black",
                                  fill = NA, size = 1),
    axis.text.y = element_text(size = 20, colour = "black"),
    axis.text.x = element_text(size = 20, colour = "black"),
    axis.title.x = element_text(size = 30, color = "black", face = "bold"),
    axis.title.y = element_text(size = 30, color = "black", face = "bold"),
    
      legend.position = ("none")) +
    coord_cartesian(ylim = c(2, 12), xlim = c(2, 12))
  return(good)
  
}

library(cowplot)
plot_graph_interval(df_data)

```

